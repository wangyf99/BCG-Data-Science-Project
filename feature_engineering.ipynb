{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "1. Import packages\n",
    "2. Load data\n",
    "3. Feature engineering\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./clean_data_after_eda.csv')\n",
    "df[\"date_activ\"] = pd.to_datetime(df[\"date_activ\"], format='%Y-%m-%d')\n",
    "df[\"date_end\"] = pd.to_datetime(df[\"date_end\"], format='%Y-%m-%d')\n",
    "df[\"date_modif_prod\"] = pd.to_datetime(df[\"date_modif_prod\"], format='%Y-%m-%d')\n",
    "df[\"date_renewal\"] = pd.to_datetime(df[\"date_renewal\"], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing feature engineering\n",
    "df['tenure'] = (df['date_end'] - df['date_activ']).dt.days / 365.25\n",
    "df['total_cons_12m'] = df['cons_12m'] + df['cons_gas_12m']\n",
    "df['avg_monthly_cons'] = df['total_cons_12m'] / 12\n",
    "df['cons_trend'] = df['cons_last_month'] - df['avg_monthly_cons']\n",
    "df['has_discount'] = (df['forecast_discount_energy'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform boolean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert has_gas from 't'/'f' to 1/0\n",
    "df['has_gas'] = df['has_gas'].map({'t': 1, 'f': 0})\n",
    "print(\"Unique values in has_gas after transformation:\", df['has_gas'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical data to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify low-frequency categories (<1% of rows)\n",
    "threshold = 0.01 * len(df)\n",
    "\n",
    "# For channel_sales\n",
    "channel_counts = df['channel_sales'].value_counts()\n",
    "print(\"Channel sales counts:\\n\", channel_counts)\n",
    "channels_to_keep = channel_counts[channel_counts >= threshold].index\n",
    "df['channel_sales'] = df['channel_sales'].apply(lambda x: x if x in channels_to_keep else 'other')\n",
    "\n",
    "# For origin_up\n",
    "origin_counts = df['origin_up'].value_counts()\n",
    "print(\"\\nOrigin up counts:\\n\", origin_counts)\n",
    "origins_to_keep = origin_counts[origin_counts >= threshold].index\n",
    "df['origin_up'] = df['origin_up'].apply(lambda x: x if x in origins_to_keep else 'other')\n",
    "\n",
    "# Create dummy variables\n",
    "df = pd.get_dummies(df, columns=['channel_sales', 'origin_up'], prefix=['channel', 'origin'], dtype=int)\n",
    "\n",
    "# Drop original columns if they still exist\n",
    "df = df.drop(columns=[col for col in ['channel_sales', 'origin_up'] if col in df.columns])\n",
    "print(\"\\nColumns after dummy creation:\\n\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treat skewness of numerical variables and plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical variables\n",
    "numerical_vars = [\n",
    "    'cons_12m', 'cons_gas_12m', 'cons_last_month', 'total_cons_12m', 'forecast_cons_12m',\n",
    "    'forecast_cons_year', 'imp_cons', 'net_margin', 'margin_gross_pow_ele', 'margin_net_pow_ele',\n",
    "    'pow_max', 'forecast_meter_rent_12m', 'forecast_price_pow_off_peak',\n",
    "    'var_year_price_off_peak_var', 'var_year_price_peak_var', 'var_year_price_mid_peak_var',\n",
    "    'var_year_price_off_peak_fix', 'var_year_price_peak_fix', 'var_year_price_mid_peak_fix',\n",
    "    'var_year_price_off_peak', 'var_year_price_peak', 'var_year_price_mid_peak',\n",
    "    'var_6m_price_off_peak_var', 'var_6m_price_peak_var', 'var_6m_price_mid_peak_var',\n",
    "    'var_6m_price_off_peak_fix', 'var_6m_price_peak_fix', 'var_6m_price_mid_peak_fix',\n",
    "    'var_6m_price_off_peak', 'var_6m_price_peak', 'var_6m_price_mid_peak',\n",
    "    'cons_trend', 'avg_monthly_cons', 'tenure'\n",
    "]\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = df[numerical_vars].apply(lambda x: skew(x.dropna()))\n",
    "print(\"Skewness of numerical variables (|skewness| > 1):\\n\", skewness[abs(skewness) > 1])\n",
    "\n",
    "# Define variables for transformation\n",
    "log_vars = [\n",
    "    'cons_12m', 'cons_gas_12m', 'cons_last_month', 'total_cons_12m', 'forecast_cons_12m',\n",
    "    'forecast_cons_year', 'imp_cons', 'net_margin', 'margin_gross_pow_ele', 'margin_net_pow_ele',\n",
    "    'pow_max', 'forecast_meter_rent_12m'\n",
    "]\n",
    "yeo_johnson_vars = [\n",
    "    'var_year_price_off_peak_var', 'var_year_price_peak_var', 'var_year_price_mid_peak_var',\n",
    "    'var_year_price_off_peak_fix', 'var_year_price_peak_fix', 'var_year_price_mid_peak_fix',\n",
    "    'var_year_price_off_peak', 'var_year_price_peak', 'var_year_price_mid_peak',\n",
    "    'var_6m_price_off_peak_var', 'var_6m_price_peak_var', 'var_6m_price_mid_peak_var',\n",
    "    'var_6m_price_off_peak_fix', 'var_6m_price_peak_fix', 'var_6m_price_mid_peak_fix',\n",
    "    'var_6m_price_off_peak', 'var_6m_price_peak', 'var_6m_price_mid_peak',\n",
    "    'cons_trend'\n",
    "]\n",
    "minmax_vars = ['tenure', 'avg_monthly_cons']\n",
    "\n",
    "# Handle missing values\n",
    "df[numerical_vars] = df[numerical_vars].fillna(df[numerical_vars].median())\n",
    "\n",
    "# Plot histograms before transformation\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, var in enumerate(log_vars + yeo_johnson_vars, 1):\n",
    "    plt.subplot(5, 7, i)\n",
    "    plt.hist(df[var].dropna(), bins=30, color='blue', alpha=0.5)\n",
    "    plt.title(f'{var} (Before)')\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Apply transformations\n",
    "# Log transformation\n",
    "for var in log_vars:\n",
    "    df[var] = np.log1p(df[var].clip(lower=0))  # Handle zeros and negatives\n",
    "\n",
    "# Yeo-Johnson transformation\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "df[