


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Shows plots in jupyter notebook
%matplotlib inline

# Set plot style
sns.set(color_codes=True)





client_df = pd.read_csv('./client_data.csv')
price_df = pd.read_csv('./price_data.csv')





client_df.head(3)


price_df.head(3)





client_df.info()


price_df.info()





client_df.describe()


price_df.describe()





# Check missing values in client_df
print('Missing values in client_df:')
print(client_df.isnull().sum())

# Check missing values in price_df
print('\nMissing values in price_df:')
print(price_df.isnull().sum())








import matplotlib.pyplot as plt
import pandas as pd

def plot_distribution(df, column, ax, bins=50, is_categorical=False, use_percentage=True):
    """
    Plot distribution of a column with stacked churn percentages or frequencies, with percentage labels for categorical data.
    
    Parameters:
    - df: DataFrame containing the data
    - column: Column name to analyze
    - ax: Matplotlib axis for plotting
    - bins: Number of bins for numerical columns (default=50)
    - is_categorical: If True, treat as categorical (default=False)
    - use_percentage: If True, plot percentages; if False, plot frequencies (default=True)
    """
    if is_categorical:
        # For categorical columns, compute churn counts
        churn_counts = df.groupby([column, 'churn']).size().unstack(fill_value=0)
        # Ensure both churn values (0 and 1) exist in columns
        for churn_val in [0, 1]:
            if churn_val not in churn_counts.columns:
                churn_counts[churn_val] = 0
        if use_percentage:
            # Calculate percentages
            churn_values = churn_counts.div(churn_counts.sum(axis=1), axis=0) * 100
            ylabel = 'Percentage'
            title = f'Distribution of {column} with Churn Percentages'
        else:
            # Use raw counts
            churn_values = churn_counts
            ylabel = 'Frequency'
            title = f'Distribution of {column} with Churn Frequencies'
        
        # Plot stacked bar plot
        churn_values.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e'])
        
        # Add percentage labels for categorical data when use_percentage=True
        if use_percentage:
            # Get the number of categories and churn values
            num_categories = len(churn_values)
            num_stacks = len(churn_values.columns)
            for i, patch in enumerate(ax.patches):
                # Get the height and position of the patch
                height = patch.get_height()
                if height > 0:  # Only add labels for non-zero heights
                    x = patch.get_x() + patch.get_width() / 2
                    y = patch.get_y() + height / 2
                    # Calculate bar and stack indices
                    bar_idx = i % num_categories  # Which category
                    stack_idx = i // num_categories  # Which churn value
                    if stack_idx < num_stacks:  # Ensure stack_idx is valid
                        value = churn_values.iloc[bar_idx, stack_idx]
                        ax.text(x, y, f'{value:.1f}%', ha='center', va='center', fontsize=8, color='white')
        
        ax.set_title(title)
        ax.set_xlabel(column)
        ax.set_ylabel(ylabel)
        ax.legend(['Non-Churned (0)', 'Churned (1)'])
    else:
        # For numerical columns, bin the data
        df['bin'] = pd.cut(df[column], bins=bins)
        # Compute churn counts for each bin
        churn_counts = df.groupby(['bin', 'churn'], observed=True).size().unstack(fill_value=0)
        if use_percentage:
            # Calculate percentages
            churn_values = churn_counts.div(churn_counts.sum(axis=1), axis=0) * 100
            ylabel = 'Percentage'
            title = f'Distribution of {column} with Churn Percentages'
        else:
            # Use raw counts
            churn_values = churn_counts
            ylabel = 'Frequency'
            title = f'Distribution of {column} with Churn Frequencies'
        
        # Plot stacked bar plot for binned data
        churn_values.plot(kind='bar', stacked=True, ax=ax, color=['#1f77b4', '#ff7f0e'])
        ax.set_title(title)
        ax.set_xlabel(f'{column} (Binned)')
        ax.set_ylabel(ylabel)
        ax.legend(['Non-Churned (0)', 'Churned (1)'])
        ax.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()





# Identify numerical columns
numerical_cols = client_df.select_dtypes(include=['int64', 'float64']).columns.drop('churn')

# Plot distributions with churn percentages and frequencies
for col in numerical_cols:
    fig, axs = plt.subplots(nrows=2, figsize=(12, 10))
    # Percentage plot
    plot_distribution(client_df, col, axs[0], bins=50, use_percentage=True)
    # Frequency plot
    plot_distribution(client_df, col, axs[1], bins=50, use_percentage=False)
    plt.show()





plot_df = client_df.copy()

# Add a temporary column with constant value 'Companies' to simulate a single category
plot_df['Companies'] = 'Companies'

# Plot single stacked bar with churn percentages
fig, ax = plt.subplots(figsize=(6, 8))
plot_distribution(plot_df, 'Companies', ax, is_categorical=True, use_percentage=True)
plt.tight_layout()
plt.show()


# Identify categorical columns
categorical_cols = ['channel_sales', 'has_gas', 'origin_up']

# Plot distributions with churn percentages and frequencies
for col in categorical_cols:
    fig, axs = plt.subplots(nrows=2, figsize=(12, 10))
    
    # Percentage plot with labels
    plot_distribution(client_df, col, axs[0], is_categorical=True, use_percentage=True)
    
    # Frequency plot
    plot_distribution(client_df, col, axs[1], is_categorical=True, use_percentage=False)
    
    plt.tight_layout(pad=2.0)
    plt.show()





# Convert date columns to datetime
date_cols = ['date_activ', 'date_end', 'date_modif_prod', 'date_renewal']
for col in date_cols:
    client_df[col] = pd.to_datetime(client_df[col])

# Extract year from date columns
for col in date_cols:
    client_df[f'{col}_year'] = client_df[col].dt.year

# Plot distributions with churn percentages and frequencies for year columns
year_cols = [f'{col}_year' for col in date_cols]
for col in year_cols:
    fig, axs = plt.subplots(nrows=2, figsize=(12, 10))
    # Percentage plot
    plot_distribution(client_df, col, axs[0], is_categorical=True, use_percentage=True)
    # Frequency plot
    plot_distribution(client_df, col, axs[1], is_categorical=True, use_percentage=False)
    plt.show()





# Aggregate price data by client ID (mean prices)
price_agg = price_df.groupby('id').agg({
    'price_off_peak_var': 'mean',
    'price_peak_var': 'mean',
    'price_mid_peak_var': 'mean',
    'price_off_peak_fix': 'mean',
    'price_peak_fix': 'mean',
    'price_mid_peak_fix': 'mean'
}).reset_index()

# Merge with client_df to include churn
price_agg = price_agg.merge(client_df[['id', 'churn']], on='id', how='left')

# Plot distributions with churn percentages and frequencies
price_cols = ['price_off_peak_var', 'price_peak_var', 'price_mid_peak_var',
              'price_off_peak_fix', 'price_peak_fix', 'price_mid_peak_fix']
for col in price_cols:
    fig, axs = plt.subplots(nrows=2, figsize=(12, 10))
    # Percentage plot
    plot_distribution(price_agg, col, axs[0], bins=10, use_percentage=True)
    # Frequency plot
    plot_distribution(price_agg, col, axs[1], bins=10, use_percentage=False)
    plt.show()


fig, axs = plt.subplots(nrows=4, figsize=(18,25))

# Plot histogram
sns.boxplot(consumption["cons_12m"], ax=axs[0])
sns.boxplot(consumption[consumption["has_gas"] == "t"]["cons_gas_12m"], ax=axs[1])
sns.boxplot(consumption["cons_last_month"], ax=axs[2])
sns.boxplot(consumption["imp_cons"], ax=axs[3])

# Remove scientific notation
for ax in axs:
    ax.ticklabel_format(style='plain', axis='x')
    # Set x-axis limit
    axs[0].set_xlim(-200000, 2000000)
    axs[1].set_xlim(-200000, 2000000)
    axs[2].set_xlim(-20000, 100000)
    plt.show()





# Compute correlation matrix
corr_matrix = client_df[numerical_cols.append(pd.Index(['churn']))].corr()

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix with Churn')
plt.show()





# Calculate the 90th percentile of margin_gross_pow_ele
margin_threshold = client_df['margin_gross_pow_ele'].quantile(0.9)
print(f'90th percentile of margin_gross_pow_ele: {margin_threshold:.2f}')

# Filter rows in the top 10% percentile
top_10_margin_df = client_df[client_df['margin_gross_pow_ele'] >= margin_threshold]
print(f'Number of clients in top 10% margin_gross_pow_ele: {len(top_10_margin_df)}')

# Summary statistics for numerical columns in top 10%
print('\nSummary statistics for numerical columns in top 10% margin_gross_pow_ele:')
numerical_cols_top = numerical_cols[numerical_cols != 'margin_gross_pow_ele']  # Exclude the target column
display(top_10_margin_df[numerical_cols_top].describe())

# Compare churn rate in top 10% vs. overall
overall_churn_rate = client_df['churn'].mean() * 100
top_10_churn_rate = top_10_margin_df['churn'].mean() * 100
print(f'Overall churn rate: {overall_churn_rate:.2f}%')
print(f'Top 10% margin churn rate: {top_10_churn_rate:.2f}%')

# Analyze categorical columns in top 10%
print('\nDistribution of categorical columns in top 10% margin_gross_pow_ele:')
for col in categorical_cols:
    print(f'\n{col}:')
    display(top_10_margin_df[col].value_counts(normalize=True) * 100)

# Merge with aggregated price data
top_10_price_df = top_10_margin_df[['id', 'churn']].merge(price_agg, on=['id', 'churn'], how='left')

# Plot distributions of key numerical columns in top 10% with percentages and frequencies
key_cols = ['cons_12m', 'cons_last_month', 'pow_max', 'margin_net_pow_ele'] + price_cols
for col in key_cols:
    fig, axs = plt.subplots(nrows=2, figsize=(12, 10))
    df_to_plot = top_10_margin_df if col in top_10_margin_df.columns else top_10_price_df
    # Percentage plot
    plot_distribution(df_to_plot, col, axs[0], bins=10, use_percentage=True)
    # Frequency plot
    plot_distribution(df_to_plot, col, axs[1], bins=10, use_percentage=False)
    plt.show()

# Correlation analysis for top 10% margin clients
corr_matrix_top = top_10_margin_df[numerical_cols.append(pd.Index(['churn']))].corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix_top, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix for Top 10% Margin_Gross_Pow_Ele Clients')
plt.show()

# Insights
print('\nInsights on high margin_gross_pow_ele clients:')
print('- High gross margins may be driven by higher subscription prices (check price_cols distributions).')
print('- Compare consumption patterns (cons_12m, cons_last_month) to see if low usage contributes.')
print('- Check if specific sales channels or contract types (channel_sales, origin_up) dominate.')
print('- Lower churn rates in top 10% suggest high-margin clients are more loyal.')
print('- Strong correlations with margin_net_pow_ele or pow_max may indicate pricing or power capacity effects.')



